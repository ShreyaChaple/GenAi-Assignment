{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7w22-5MUUUZq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1\n"
      ],
      "metadata": {
        "id": "k6sJCbpocB1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/Auto_Regressive_Model_Diffusion_Model_V_1.0.xlsx'\n",
        "\n",
        "data = pd.read_excel(file_path, sheet_name='Base_Data_Set')"
      ],
      "metadata": {
        "id": "LhtpG0hzUWUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[['Symptoms - 1', 'Symptoms - 2', 'Symptoms - 3', 'Other Symptoms']]\n"
      ],
      "metadata": {
        "id": "pPrW2K4eUjXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1hAbUFKGcEWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "symptom_dict = {}"
      ],
      "metadata": {
        "id": "w8TjBk07UzU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2"
      ],
      "metadata": {
        "id": "epjJ_XMzcFsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_symptoms(row, symptom_dict):\n",
        "    \"\"\"Parses symptoms from a row and updates the dictionary.\"\"\"\n",
        "    symptoms = {\n",
        "        'Symptoms - 1': row['Symptoms - 1'],\n",
        "        'Symptoms - 2': row['Symptoms - 2'],\n",
        "        'Symptoms - 3': row['Symptoms - 3'],\n",
        "        'Other Symptoms': row['Other Symptoms']\n",
        "    }\n",
        "\n",
        "    for symptom_name, symptom_value in symptoms.items():\n",
        "        if pd.notna(symptom_value):  # Only add non-NaN values\n",
        "            if symptom_name not in symptom_dict:\n",
        "                symptom_dict[symptom_name] = set()\n",
        "            symptom_dict[symptom_name].add(symptom_value)"
      ],
      "metadata": {
        "id": "isfaKDEFU0Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_dict(symptom_dict):\n",
        "    \"\"\"Displays the current state of the symptom dictionary.\"\"\"\n",
        "    for symptom, variations in symptom_dict.items():\n",
        "        print(f\"{symptom}: {', '.join(variations)}\")"
      ],
      "metadata": {
        "id": "3AjYyMROU3YC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HYdmeaskVOT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_missing_columns(symptom_dict, expected_columns):\n",
        "    \"\"\"Checks and prints missing columns (loss).\"\"\"\n",
        "    missing_columns = [col for col in expected_columns if col not in symptom_dict]\n",
        "    if missing_columns:\n",
        "        print(f\"Missing columns (Loss): {missing_columns}\")\n",
        "    else:\n",
        "        print(\"All expected columns are present.\")"
      ],
      "metadata": {
        "id": "dDHagIDaU5EO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _, row in data.iterrows():\n",
        "    parse_symptoms(row, symptom_dict)"
      ],
      "metadata": {
        "id": "nRaU7a6ZU6jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Initial Symptom Dictionary:\")\n",
        "display_dict(symptom_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNScl6IsU794",
        "outputId": "1bda69e1-1f22-4ed6-c539-d623c45e1272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Symptom Dictionary:\n",
            "Symptoms - 1: Fever, Y, Mild\n",
            "Symptoms - 2: N, Cough, Mild\n",
            "Symptoms - 3: N, Mild, Cold\n",
            "Other Symptoms: Vertigo, Nausia, Text, Vertigo, Head Ache, Shivering, Nausia, Body Ache, Sickness\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "expected_columns = ['Symptoms - 1', 'Symptoms - 2', 'Symptoms - 3', 'Other Symptoms']\n",
        "check_missing_columns(symptom_dict, expected_columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPxaCSaFU9YO",
        "outputId": "eb8573b7-f82b-45a7-9e0c-a9d568f5caf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All expected columns are present.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for _, row in data.iterrows():\n",
        "    parse_symptoms(row, symptom_dict)\n"
      ],
      "metadata": {
        "id": "Q1g_lOK2U-qC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nEnhanced Symptom Dictionary:\")\n",
        "display_dict(symptom_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKs8kxj2VAUt",
        "outputId": "301a422e-e35b-46d6-efec-4d64eac5e3a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enhanced Symptom Dictionary:\n",
            "Symptoms - 1: Fever, Y, Mild\n",
            "Symptoms - 2: N, Cough, Mild\n",
            "Symptoms - 3: N, Mild, Cold\n",
            "Other Symptoms: Vertigo, Nausia, Text, Vertigo, Head Ache, Shivering, Nausia, Body Ache, Sickness\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3\n"
      ],
      "metadata": {
        "id": "6oZ9Y47CcKjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "symptom_dict = {\n",
        "    \"S1\": {\"Fever\": [\"mild\", \"low\", \"high\"]},\n",
        "    \"S2\": {\"Cough\": [\"mild\", \"low\", \"high\"]},\n",
        "    \"S3\": {\"Cold\": [\"mild\", \"low\", \"high\"]},\n",
        "    \"S4\": {\"Body Ache\": {}},\n",
        "    \"S5\": {\"Cold\": {}},\n",
        "    \"S6\": {\"Shivering\": [\"mild\", \"high\", \"intermittent\"]}\n",
        "}"
      ],
      "metadata": {
        "id": "HPIQGQuSVBkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Define function to parse, print Loss, and enhance the dictionary\n",
        "def print_loss_and_enhance_dictionary(data, symptom_dict):\n",
        "    loss = []  # Track missing attributes\n",
        "    for _, row in data.iterrows():\n",
        "\n",
        "        # Check if the column name is 'SrNo' or 'Sr.No'\n",
        "        sr_no = row.get('SrNo') if 'SrNo' in row else row.get('Sr.No')\n",
        "\n",
        "        # If sr_no is still None, it means neither column exists\n",
        "        if sr_no is None:\n",
        "            raise KeyError(\"Neither 'SrNo' nor 'Sr.No' column found in the DataFrame.\")\n",
        "\n",
        "        patient_id = row['Patient_Id']\n",
        "        observation = row['Observation']\n",
        "        particulars = row['Particulars']\n",
        "        time_period = row['Time Period']\n",
        "        location = row[['City', 'State', 'Country', 'Pincode']].to_dict()\n",
        "\n",
        "        # If there is a valid observation, check against the dictionary\n",
        "        if pd.notna(observation):\n",
        "            symptoms = observation.split(\", \")\n",
        "            for symptom in symptoms:\n",
        "                found = False\n",
        "                for key, symptom_data in symptom_dict.items():\n",
        "                    if symptom in symptom_data:\n",
        "                        # Symptom found, attach attributes (only to dictionary types)\n",
        "                        if isinstance(symptom_data[symptom], dict):\n",
        "                            symptom_dict[key][symptom].update({\n",
        "                                \"Particulars\": particulars,\n",
        "                                \"Time Period\": time_period,\n",
        "                                \"Location\": location\n",
        "                            })\n",
        "                        found = True\n",
        "                        break\n",
        "                if not found:\n",
        "                    loss.append((sr_no, patient_id, symptom))  # Track loss if symptom not found\n",
        "\n",
        "    # Print the loss in Step 2\n",
        "    print(\"Loss found in Step 2:\")\n",
        "    if loss:\n",
        "        for sr_no, patient_id, symptom in loss:\n",
        "            print(f\"SrNo: {sr_no}, Patient_Id: {patient_id}, Symptom: {symptom} (Not found in dictionary)\")\n",
        "    else:\n",
        "        print(\"No loss found. All symptoms matched the dictionary.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "CERURlyLcrVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Print the enhanced dictionary\n",
        "print(\"\\nEnhanced Symptom Dictionary:\")\n",
        "for key, symptoms in symptom_dict.items():\n",
        "  print(f\"{key}: {symptoms}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXyVl0pggyct",
        "outputId": "d38cc870-4c9a-4799-cf8a-e761ee829798"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enhanced Symptom Dictionary:\n",
            "S1: {'Fever': ['mild', 'low', 'high']}\n",
            "S2: {'Cough': ['mild', 'low', 'high']}\n",
            "S3: {'Cold': ['mild', 'low', 'high']}\n",
            "S4: {'Body Ache': {}}\n",
            "S5: {'Cold': {}}\n",
            "S6: {'Shivering': ['mild', 'high', 'intermittent']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_loss_of_attributes(symptom_dict):\n",
        "    attribute_loss = 0\n",
        "    for key, symptoms in symptom_dict.items():\n",
        "        for symptom, details in symptoms.items():\n",
        "            if isinstance(details, dict):\n",
        "                required_keys = [\"Particulars\", \"Time Period\", \"Location\"]\n",
        "                if any(key not in details for key in required_keys):\n",
        "                    attribute_loss += 1\n",
        "\n",
        "    print(f\"\\nLoss of attributes is {attribute_loss}\")\n",
        "    if attribute_loss == 0:\n",
        "        print(\"No attribute loss, all attributes were correctly attached.\")"
      ],
      "metadata": {
        "id": "3AZTXjMycxu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_loss_of_attributes(symptom_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn6WTRPEge8G",
        "outputId": "29db49eb-cc38-44b9-8281-7430a0c81b74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loss of attributes is 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4"
      ],
      "metadata": {
        "id": "1xuJt0JBhMr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "import os"
      ],
      "metadata": {
        "id": "mIpA4rEQgg6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SymptomParser:\n",
        "    def __init__(self):\n",
        "        self.symptom_dict = {}\n",
        "        self.loss = []\n",
        "        self.loss_of_attributes = 0  # Initialize loss of attributes\n",
        "\n",
        "    def read_data(self, file_path):\n",
        "        \"\"\"Reads data from various formats and enhances the dictionary.\"\"\"\n",
        "        file_extension = os.path.splitext(file_path)[1]\n",
        "\n",
        "        if file_extension == '.csv':\n",
        "            self.read_csv(file_path)\n",
        "        elif file_extension == '.tsv':\n",
        "            self.read_tsv(file_path)\n",
        "        elif file_extension == '.json':\n",
        "            self.read_json(file_path)\n",
        "        elif file_extension == '.xml':\n",
        "            self.read_xml(file_path)\n",
        "        else:\n",
        "            print(\"Unsupported file format.\")\n",
        "\n",
        "    def read_csv(self, file_path):\n",
        "        df = pd.read_csv(file_path)\n",
        "        self.enhance_dictionary(df)\n",
        "\n",
        "    def read_tsv(self, file_path):\n",
        "        df = pd.read_csv(file_path, sep='\\t')\n",
        "        self.enhance_dictionary(df)\n",
        "\n",
        "    def read_json(self, file_path):\n",
        "        with open(file_path) as f:\n",
        "            data = json.load(f)\n",
        "            df = pd.json_normalize(data)\n",
        "            self.enhance_dictionary(df)\n",
        "\n",
        "    def read_xml(self, file_path):\n",
        "        tree = ET.parse(file_path)\n",
        "        root = tree.getroot()\n",
        "        data = []\n",
        "\n",
        "        # Convert XML to a list of dictionaries\n",
        "        for item in root.findall('.//item'):  # Adjust the tag based on your XML structure\n",
        "            entry = {}\n",
        "            for child in item:\n",
        "                entry[child.tag] = child.text\n",
        "            data.append(entry)\n",
        "\n",
        "        df = pd.DataFrame(data)\n",
        "        self.enhance_dictionary(df)\n",
        "\n",
        "    def enhance_dictionary(self, df):\n",
        "        \"\"\"Enhances the dictionary based on the DataFrame.\"\"\"\n",
        "        for index, row in df.iterrows():\n",
        "            for column, value in row.items():\n",
        "                if column not in self.symptom_dict:\n",
        "                    self.symptom_dict[column] = set()\n",
        "                self.symptom_dict[column].add(value)\n",
        "\n",
        "        self.loss_of_attributes = 0  # Reset the loss of attributes\n",
        "\n",
        "    def dump_dictionary(self, filename):\n",
        "        \"\"\"Dumps the dictionary to a JSON file.\"\"\"\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(self.symptom_dict, f, indent=4)\n",
        "\n",
        "    def print_dictionary(self):\n",
        "        \"\"\"Prints the symptom dictionary in a structured format.\"\"\"\n",
        "        print(\"\\nSymptom Dictionary:\")\n",
        "        for key, value in self.symptom_dict.items():\n",
        "            print(f\"\\t'{key}': {list(value)}\")\n",
        "\n",
        "    def manual_editing(self):\n",
        "        \"\"\"Allows manual editing of the dictionary.\"\"\"\n",
        "        while True:\n",
        "            print(\"\\nCurrent Dictionary:\")\n",
        "            self.print_dictionary()\n",
        "            edit_key = input(\"\\nEnter the key to edit (or type 'exit' to finish): \")\n",
        "            if edit_key.lower() == 'exit':\n",
        "                break\n",
        "\n",
        "            if edit_key in self.symptom_dict:\n",
        "                new_values = input(\"Enter new values (comma separated): \")\n",
        "                self.symptom_dict[edit_key] = set(new_values.split(\",\"))\n",
        "            else:\n",
        "                print(\"Key not found. Try again.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = SymptomParser()\n",
        "\n",
        "    print(\"1. Read and Create Dictionary\")\n",
        "    file_path = input(\"Enter the data file path (CSV, TSV, JSON, XML): \")\n",
        "    parser.read_data(file_path)\n",
        "\n",
        "    print(f\"Dictionary Loss is: {parser.loss_of_attributes}\")\n",
        "\n",
        "    print(\"2. Dump Dictionary\")\n",
        "    dump_filename = input(\"Enter the filename to save the dictionary (e.g., output.json): \")\n",
        "    parser.dump_dictionary(dump_filename)\n",
        "\n",
        "    print(\"3. Print Data Sets\")\n",
        "    parser.print_dictionary()\n",
        "\n",
        "    print(\"4. Allow editing and reparsing of data\")\n",
        "    parser.manual_editing()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZZFXt13hQlu",
        "outputId": "ef0f8a48-49a0-4b0b-d239-21289ac9f0b9"
      },
      "execution_count": 50,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Read and Create Dictionary\n",
            "Enter the data file path (CSV, TSV, JSON, XML): /content/Auto_Regressive_Model_Diffusion_Model_V_1.0.xlsx\n",
            "Unsupported file format.\n",
            "Dictionary Loss is: 0\n",
            "2. Dump Dictionary\n",
            "Enter the filename to save the dictionary (e.g., output.json): output.json\n",
            "3. Print Data Sets\n",
            "\n",
            "Symptom Dictionary:\n",
            "4. Allow editing and reparsing of data\n",
            "\n",
            "Current Dictionary:\n",
            "\n",
            "Symptom Dictionary:\n",
            "\n",
            "Enter the key to edit (or type 'exit' to finish): Symptoms\n",
            "Key not found. Try again.\n",
            "\n",
            "Current Dictionary:\n",
            "\n",
            "Symptom Dictionary:\n",
            "\n",
            "Enter the key to edit (or type 'exit' to finish): exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zBBTz6fqhSxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JSElRYODhVEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oT1FoFSnhWjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M4gqP_cWhXv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P9VXsC5BhbiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "llvtNL_mhhBE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}